{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from https://www.nporadio2.nl/top2000\n",
    "df = pd.read_csv(\"../source/nporadio2-Top-2000-2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_suffixes = [\" (Albumversie)\", \" (Live)\"]\n",
    "\n",
    "df['cleaned_title'] = df['titel']\n",
    "\n",
    "for suffix in remove_suffixes:\n",
    "\tdf['cleaned_title'] = df['cleaned_title'].str.replace(suffix, '')\n",
    "\n",
    "def words(title, with_parends):\n",
    "\t'''\n",
    "\twords('Street Spirit (Fade Out)', True) -> ['Street', 'Spirit', 'Fade', 'Out']\n",
    "\twords('Street Spirit (Fade Out)', False) -> ['Street', 'Spirit']\n",
    "\t'''\n",
    "\ttitle = title.strip()\n",
    "\tif not with_parends:\n",
    "\t\ttitle = re.sub(r'\\([^)]*\\)', '', title).strip()\n",
    "\t\n",
    "\treturn [word.strip(\"()\") for word in re.split(r'\\s+', title)]\n",
    "\n",
    "df['starts_with'] = df['cleaned_title'].apply(lambda x: words(x, False)[0].lower())\n",
    "df['ends_with'] = df['cleaned_title'].apply(lambda x: words(x, False)[-1].lower())\n",
    "\n",
    "df['starts_with_inc_parends'] = df['cleaned_title'].apply(lambda x: words(x, True)[0].lower())\n",
    "df['ends_with_inc_parends'] = df['cleaned_title'].apply(lambda x: words(x, True)[-1].lower())\n",
    "\n",
    "with open(\"top2000-labels.txt\", \"w\") as f:\n",
    "\tf.write(\"\\n\".join(df['cleaned_title']))\n",
    "\n",
    "labelled_edges = []\n",
    "\n",
    "for i, src in df.iterrows():\n",
    "\tlinking_words = set([src['ends_with'], src['ends_with_inc_parends']])\n",
    "\ttargets = df[df['starts_with'].isin(linking_words) | df['starts_with_inc_parends'].isin(linking_words)]\n",
    "\tfor j, tar in targets.iterrows():\n",
    "\t\tif src['cleaned_title'] == tar['cleaned_title']:\n",
    "\t\t\tcontinue\n",
    "\t\tlabelled_edges.append(((i, src['cleaned_title']), (j, tar['cleaned_title'])))\n",
    "\n",
    "with open(\"top2000-graph.txt\", \"w\") as f:\n",
    "\tf.write(str(len(df['cleaned_title'])) + \"\\n\")\n",
    "\n",
    "\tfor (i, _), (j, _) in labelled_edges:\n",
    "\t\tf.write(f'{i} {j}\\n')\n",
    "\n",
    "with open(\"top2000-labelled-edges.txt\", \"w\") as f:\n",
    "\tfor (i, src_title), (j, tar_title) in labelled_edges:\n",
    "\t\tf.write(f\"{src_title} -> {tar_title} ({i} -> {j})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read graph. vertices: 2000, edges: 3465\n",
      "Search mode: BRUTE_FORCE\n",
      "Longest path length: 30\n",
      "Longest path: 114 1644 458 1359 1129 556 1831 1994 1045 1661 1344 1682 879 1040 670 100 77 1813 1915 880 1372 250 1819 1747 1079 1837 208 1922 120 814 1712 \n",
      "Time: 1.049675s\n",
      "\n",
      "Sign Of The Times\n",
      "Times Were When\n",
      "When Doves Cry\n",
      "Cry Baby\n",
      "Baby Can I Hold You\n",
      "You Shook Me All Night Long\n",
      "Long Cool Woman (In A Black Dress)\n",
      "Woman\n",
      "Woman In Love\n",
      "Love Is All\n",
      "All You Need Is Love\n",
      "Love Me Just A Little Bit More (Totally Hooked On You)\n",
      "You Need To Calm Down\n",
      "Down Down\n",
      "Down Under\n",
      "Under The Bridge\n",
      "Bridge Over Troubled Water\n",
      "Water Of Love\n",
      "Love Really Hurts Without You\n",
      "You\n",
      "You Can't Hurry Love\n",
      "Love You More\n",
      "More Than This\n",
      "This Charming Man\n",
      "Man On The Moon\n",
      "Moon Over Bourbon Street\n",
      "Street Spirit (Fade Out)\n",
      "Out In The Fields\n",
      "Fields Of Gold\n",
      "Gold\n",
      "Gold On The Ceiling\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "with open(\"top2000-graph.txt\", \"r\") as f:\n",
    "\tresult = subprocess.run(['../../lpath','BRUTE_FORCE'], stdin=f, stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "path = list(map(int, re.search(r'Longest path: (.+)\\s', result.stdout).group(1).split()))\n",
    "titles = [df.iloc[i]['cleaned_title'] for i in path]\n",
    "\n",
    "print(result.stdout)\n",
    "print('\\n'.join(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read graph. vertices: 2000, edges: 3465\n",
      "Search mode: DFBNB\n",
      "Longest path length: 30\n",
      "Longest path: 114 1644 458 1359 1129 556 1831 1994 1045 1661 1344 1682 879 1040 670 100 77 1813 1915 880 1372 250 1819 1747 1079 1837 208 1922 120 814 1712 \n",
      "Time: 6.971052s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "with open(\"top2000-graph.txt\", \"r\") as f:\n",
    "\tresult = subprocess.run(['../../lpath','DFBNB'], stdin=f, stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "print(result.stdout)\n",
    "\n",
    "\n",
    "# Depth first Branch and Bound takes longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
