{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"network.xlsx\",\n",
    "\t\t\t\t\t\t\t\t\t header=None,\n",
    "\t\t\t\t\t\t\t\t\t names = [\"first\", \"middle\", \"last\"]).fillna(\"\")\n",
    "\n",
    "df['title'] = df.apply(lambda row: ' '.join(row) if row[\"middle\"] != \"\" else row[\"first\"] + \" \" + row[\"last\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rob-top2000-labels.txt\", \"w\") as f:\n",
    "\tf.write(\"\\n\".join(df['title']))\n",
    "\n",
    "labelled_edges = []\n",
    "\n",
    "for i, src in df.iterrows():\n",
    "\tlinking_word = src['last']\n",
    "\ttargets = df[df['first'] == linking_word]\n",
    "\tfor j, tar in targets.iterrows():\n",
    "\t\tlabelled_edges.append(((i, src['title']), (j, tar['title'])))\n",
    "\n",
    "with open(\"rob-top2000-graph.txt\", \"w\") as f:\n",
    "\tf.write(str(len(df['title'])) + \"\\n\")\n",
    "\n",
    "\tfor (i, _), (j, _) in labelled_edges:\n",
    "\t\tf.write(f'{i} {j}\\n')\n",
    "\n",
    "with open(\"rob-top2000-labelled-edges.txt\", \"w\") as f:\n",
    "\tfor (i, src_title), (j, tar_title) in labelled_edges:\n",
    "\t\tf.write(f\"{src_title} -> {tar_title} ({i} -> {j})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3438, 1000, 991, 1982)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undirected_edges = {frozenset([i, j]) for (i, _), (j, _) in labelled_edges[:1000]}\n",
    "undirected_edges_list = [tuple(e) for e in undirected_edges if len(e) > 1]\n",
    "\n",
    "directed_undirected_edges_list = undirected_edges_list + [(t, s) for (s, t) in undirected_edges_list]\n",
    "\n",
    "len(labelled_edges), len(undirected_edges), len(undirected_edges_list), len(directed_undirected_edges_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (3990666502.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    f.write(f\"p sp {len(df[\"title\"])} {len(directed_undirected_edges_list)}\\n\")\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "with open(\"rob-top2000-KALP.dimacs\", \"w\") as f:\n",
    "    f.write(f\"p sp {len(df[\"title\"])} {len(directed_undirected_edges_list)}\\n\")\n",
    "\n",
    "    for s, t in directed_undirected_edges_list:\n",
    "        f.write(f\"a {s + 1} {t + 1} 1\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read graph. vertices: 1573, edges: 3438\n",
      "Search mode: SMART_FORCE\n",
      "Longest path length: 42\n",
      "Longest path: 939 827 549 331 1366 1149 513 880 858 1507 684 832 855 935 1220 1002 1054 1376 1569 1382 1438 1345 240 152 485 931 876 1570 988 298 780 1454 900 1126 564 1073 398 857 1271 610 851 1014 735 \n",
      "Time: 2.940488s\n",
      "\n",
      "Sign Of The Times\n",
      "Times Were When\n",
      "When Doves Cry\n",
      "Cry  Baby\n",
      "Baby Can I Hold You\n",
      "You Can't Hurry Love\n",
      "Love You More\n",
      "More Than This\n",
      "This Charming Man\n",
      "Man I Feel Like A Woman\n",
      "Woman In Love\n",
      "Love Is All\n",
      "All For Nothing\n",
      "Nothing Compares 2 You\n",
      "You 've Got The Love\n",
      "Love  Story\n",
      "Story Of My Life\n",
      "Life 's What You Make It\n",
      "It 's The End Of The World As We Know It\n",
      "It Must Have Been Love\n",
      "Love Really Hurts Without You\n",
      "You Need To Calm Down\n",
      "Down  Down\n",
      "Down  Under\n",
      "Under The Bridge\n",
      "Bridge Over Troubled Water\n",
      "Water Of Love\n",
      "Love Me Just A Little Bit More\n",
      "More Than A Feeling\n",
      "Feeling  Good\n",
      "Good 4 You\n",
      "You Shook Me All Night Long\n",
      "Long Train Running\n",
      "Running To Stand Still\n",
      "Still Loving You\n",
      "You Are So Beautiful\n",
      "Beautiful  Goodbye\n",
      "Goodbye My Lover\n",
      "Lover Of The Light\n",
      "Light My Fire\n",
      "Fire And Rain\n",
      "Rain Down On Me\n",
      "Me Gustas Tu\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "with open(\"rob-top2000-graph.txt\", \"r\") as f:\n",
    "\tresult = subprocess.run(['../../lpath','SMART_FORCE'], stdin=f, stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "path = list(map(int, re.search(r'Longest path: (.+)\\s', result.stdout).group(1).split()))\n",
    "titles = [df.iloc[i]['title'] for i in path]\n",
    "\n",
    "print(result.stdout)\n",
    "print('\\n'.join(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "with open(\"top2000-graph.txt\", \"r\") as f:\n",
    "\tresult = subprocess.run(['../../lpath','DFBNB'], stdin=f, stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "print(result.stdout)\n",
    "\n",
    "\n",
    "# Depth first Branch and Bound takes longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'brute' from '/Users/billy/LongestPath/LongestPath/brute/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "# Enable imports form top-level of project (edit top_level_path accordingly)\n",
    "import os\n",
    "import sys\n",
    "top_level_path = os.path.abspath(os.path.join('..', '..'))\n",
    "if top_level_path not in sys.path:\n",
    "\tsys.path.append(top_level_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(939, 827), (827, 549), (549, 331), (331, 1366), (1366, 1149), (1149, 513), (513, 880), (880, 858), (858, 1507), (1507, 684), (684, 832), (832, 855), (855, 935), (935, 1220), (1220, 1002), (1002, 1054), (1054, 1376), (1376, 1569), (1569, 1382), (1382, 1438), (1438, 1345), (1345, 240), (240, 152), (152, 485), (485, 931), (931, 876), (876, 1570), (1570, 988), (988, 298), (298, 780), (780, 1454), (1454, 900), (900, 1126), (1126, 564), (564, 1073), (1073, 398), (398, 857), (857, 1271), (1271, 610), (610, 851), (851, 1014), (1014, 735)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"rob-top2000-graph.txt\", \"r\") as f:\n",
    "\tvertices, edges = from_string(f.read())\n",
    "\n",
    "path_edges = list(zip(path, path[1:]))\n",
    "print(path_edges)\n",
    "\n",
    "data = {\n",
    "\t\"nodes\": [{\"id\": df.iloc[i]['title'], \"group\": 2 if i in path else 1} for i in range(vertices)],\n",
    "\t\"links\": [{\"source\": df.iloc[i]['title'], \"target\": df.iloc[j]['title'], \"value\": 1 if (i,j) in path_edges else 0} for (i,j) in edges],\n",
    "}\n",
    "\n",
    "with open('graph.json', 'w', encoding='utf-8') as f:\n",
    "\tjson.dump(data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [df.iloc[i]['first'] for i in range(vertices)] + [df.iloc[i]['last'] for i in range(vertices)]\n",
    "words = list(set(words))\n",
    "path_words = set([df.iloc[i]['first'] for i in path] + [df.iloc[i]['last'] for i in path])\n",
    "\n",
    "title_links = [\n",
    "\t{\n",
    "\t\t\"source\": row[\"first\"],\n",
    "\t\t\"target\": row[\"last\"],\n",
    "\t\t\"title\": row[\"title\"],\n",
    "\t\t\"value\": 1 if row[\"title\"] in titles else 0,\n",
    "\t} for _, row in df.iterrows()]\n",
    "\n",
    "dual_data = {\n",
    "\t\"nodes\": [{\"id\": word, \"group\": 1 if word in path_words else 0} for word in words],\n",
    "\t\"links\": title_links,\n",
    "}\n",
    "\n",
    "with open('dual_graph.json', 'w', encoding='utf-8') as f:\n",
    "\tjson.dump(dual_data, f, ensure_ascii=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
